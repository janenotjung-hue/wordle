{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imitation.data import rollout\n",
    "from imitation.data.wrappers import RolloutInfoWrapper\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import numpy as np\n",
    "from Wordle import WordleEnv\n",
    "from stable_baselines3.common import monitor\n",
    "\n",
    "# Create a vectorized environment for training with `imitation`\n",
    "\n",
    "env = monitor.Monitor(WordleEnv())\n",
    "venv = DummyVecEnv([lambda: RolloutInfoWrapper(env)])  # Wrap a single environment -- only useful for simple testing like this\n",
    "venv.render_mode=\"human\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "rollouts = np.load('data/trajectories_all.npy', allow_pickle=True)\n",
    "transitions = rollout.flatten_trajectories_with_rew(rollouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward before training: -8.18\n"
     ]
    }
   ],
   "source": [
    "from imitation.algorithms import bc\n",
    "\n",
    "bc_trainer = bc.BC(\n",
    "    observation_space=env.observation_space,\n",
    "    action_space=env.action_space,\n",
    "    demonstrations=transitions,\n",
    "    rng=rng,\n",
    ")\n",
    "reward_before_training, _ = evaluate_policy(bc_trainer.policy, venv, 100, return_episode_rewards=True)\n",
    "print(f\"Reward before training: {np.mean(reward_before_training)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "161496batch [2:25:47, 58.40batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 161500    |\n",
      "|    ent_loss       | -3.91e-05 |\n",
      "|    entropy        | 0.0391    |\n",
      "|    epoch          | 656       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.77e+05  |\n",
      "|    loss           | 0.0336    |\n",
      "|    neglogp        | 0.0336    |\n",
      "|    prob_true_act  | 0.979     |\n",
      "|    samples_so_far | 5168032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "161998batch [2:25:57, 53.29batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 162000    |\n",
      "|    ent_loss       | -1.66e-06 |\n",
      "|    entropy        | 0.00166   |\n",
      "|    epoch          | 658       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.77e+05  |\n",
      "|    loss           | 0.000147  |\n",
      "|    neglogp        | 0.000149  |\n",
      "|    prob_true_act  | 1         |\n",
      "|    samples_so_far | 5184032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162496batch [2:26:06, 54.94batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 162500    |\n",
      "|    ent_loss       | -4.19e-06 |\n",
      "|    entropy        | 0.00419   |\n",
      "|    epoch          | 660       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.77e+05  |\n",
      "|    loss           | 0.000623  |\n",
      "|    neglogp        | 0.000628  |\n",
      "|    prob_true_act  | 0.999     |\n",
      "|    samples_so_far | 5200032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162994batch [2:26:15, 57.34batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 163000    |\n",
      "|    ent_loss       | -1.42e-06 |\n",
      "|    entropy        | 0.00142   |\n",
      "|    epoch          | 662       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.78e+05  |\n",
      "|    loss           | 0.000129  |\n",
      "|    neglogp        | 0.000131  |\n",
      "|    prob_true_act  | 1         |\n",
      "|    samples_so_far | 5216032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163494batch [2:26:24, 60.12batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 163500    |\n",
      "|    ent_loss       | -0.000102 |\n",
      "|    entropy        | 0.102     |\n",
      "|    epoch          | 664       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.78e+05  |\n",
      "|    loss           | 0.11      |\n",
      "|    neglogp        | 0.111     |\n",
      "|    prob_true_act  | 0.939     |\n",
      "|    samples_so_far | 5232032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163996batch [2:26:32, 59.12batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 164000    |\n",
      "|    ent_loss       | -3.08e-05 |\n",
      "|    entropy        | 0.0308    |\n",
      "|    epoch          | 666       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.78e+05  |\n",
      "|    loss           | 0.0411    |\n",
      "|    neglogp        | 0.0411    |\n",
      "|    prob_true_act  | 0.977     |\n",
      "|    samples_so_far | 5248032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164499batch [2:26:41, 56.28batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 164500    |\n",
      "|    ent_loss       | -1.08e-06 |\n",
      "|    entropy        | 0.00108   |\n",
      "|    epoch          | 668       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.78e+05  |\n",
      "|    loss           | 9.06e-05  |\n",
      "|    neglogp        | 9.17e-05  |\n",
      "|    prob_true_act  | 1         |\n",
      "|    samples_so_far | 5264032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164999batch [2:26:57, 18.93batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 165000    |\n",
      "|    ent_loss       | -4.13e-06 |\n",
      "|    entropy        | 0.00413   |\n",
      "|    epoch          | 670       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.78e+05  |\n",
      "|    loss           | 0.000427  |\n",
      "|    neglogp        | 0.000431  |\n",
      "|    prob_true_act  | 1         |\n",
      "|    samples_so_far | 5280032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "165496batch [2:27:05, 60.57batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 165500    |\n",
      "|    ent_loss       | -3.64e-06 |\n",
      "|    entropy        | 0.00364   |\n",
      "|    epoch          | 672       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.78e+05  |\n",
      "|    loss           | 0.00036   |\n",
      "|    neglogp        | 0.000363  |\n",
      "|    prob_true_act  | 1         |\n",
      "|    samples_so_far | 5296032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "165998batch [2:27:14, 57.10batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "| batch_size        | 32       |\n",
      "| bc/               |          |\n",
      "|    batch          | 166000   |\n",
      "|    ent_loss       | -2.9e-06 |\n",
      "|    entropy        | 0.0029   |\n",
      "|    epoch          | 674      |\n",
      "|    l2_loss        | 0        |\n",
      "|    l2_norm        | 1.78e+05 |\n",
      "|    loss           | 0.000263 |\n",
      "|    neglogp        | 0.000266 |\n",
      "|    prob_true_act  | 1        |\n",
      "|    samples_so_far | 5312032  |\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "166496batch [2:27:23, 61.09batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 166500    |\n",
      "|    ent_loss       | -3.49e-05 |\n",
      "|    entropy        | 0.0349    |\n",
      "|    epoch          | 676       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.78e+05  |\n",
      "|    loss           | 0.0175    |\n",
      "|    neglogp        | 0.0176    |\n",
      "|    prob_true_act  | 0.986     |\n",
      "|    samples_so_far | 5328032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "166998batch [2:27:31, 55.01batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 167000    |\n",
      "|    ent_loss       | -1.35e-06 |\n",
      "|    entropy        | 0.00135   |\n",
      "|    epoch          | 678       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.79e+05  |\n",
      "|    loss           | 0.000122  |\n",
      "|    neglogp        | 0.000123  |\n",
      "|    prob_true_act  | 1         |\n",
      "|    samples_so_far | 5344032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167495batch [2:27:40, 58.20batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "| batch_size        | 32       |\n",
      "| bc/               |          |\n",
      "|    batch          | 167500   |\n",
      "|    ent_loss       | -1.5e-06 |\n",
      "|    entropy        | 0.0015   |\n",
      "|    epoch          | 680      |\n",
      "|    l2_loss        | 0        |\n",
      "|    l2_norm        | 1.79e+05 |\n",
      "|    loss           | 0.000137 |\n",
      "|    neglogp        | 0.000139 |\n",
      "|    prob_true_act  | 1        |\n",
      "|    samples_so_far | 5360032  |\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167998batch [2:27:49, 57.76batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 168000    |\n",
      "|    ent_loss       | -1.57e-06 |\n",
      "|    entropy        | 0.00157   |\n",
      "|    epoch          | 682       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.79e+05  |\n",
      "|    loss           | 0.000139  |\n",
      "|    neglogp        | 0.00014   |\n",
      "|    prob_true_act  | 1         |\n",
      "|    samples_so_far | 5376032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168497batch [2:27:57, 60.18batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "| batch_size        | 32       |\n",
      "| bc/               |          |\n",
      "|    batch          | 168500   |\n",
      "|    ent_loss       | -2.2e-05 |\n",
      "|    entropy        | 0.022    |\n",
      "|    epoch          | 684      |\n",
      "|    l2_loss        | 0        |\n",
      "|    l2_norm        | 1.79e+05 |\n",
      "|    loss           | 0.0353   |\n",
      "|    neglogp        | 0.0353   |\n",
      "|    prob_true_act  | 0.979    |\n",
      "|    samples_so_far | 5392032  |\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168994batch [2:28:05, 59.47batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 169000    |\n",
      "|    ent_loss       | -8.81e-06 |\n",
      "|    entropy        | 0.00881   |\n",
      "|    epoch          | 686       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.79e+05  |\n",
      "|    loss           | 0.00113   |\n",
      "|    neglogp        | 0.00114   |\n",
      "|    prob_true_act  | 0.999     |\n",
      "|    samples_so_far | 5408032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169494batch [2:28:14, 60.93batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 169500    |\n",
      "|    ent_loss       | -3.78e-06 |\n",
      "|    entropy        | 0.00378   |\n",
      "|    epoch          | 689       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.79e+05  |\n",
      "|    loss           | 0.000378  |\n",
      "|    neglogp        | 0.000382  |\n",
      "|    prob_true_act  | 1         |\n",
      "|    samples_so_far | 5424032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169998batch [2:28:22, 60.19batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 170000    |\n",
      "|    ent_loss       | -8.92e-07 |\n",
      "|    entropy        | 0.000892  |\n",
      "|    epoch          | 691       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.79e+05  |\n",
      "|    loss           | 7.53e-05  |\n",
      "|    neglogp        | 7.62e-05  |\n",
      "|    prob_true_act  | 1         |\n",
      "|    samples_so_far | 5440032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170499batch [2:28:32, 44.52batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 170500    |\n",
      "|    ent_loss       | -2.53e-05 |\n",
      "|    entropy        | 0.0253    |\n",
      "|    epoch          | 693       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.79e+05  |\n",
      "|    loss           | 0.0188    |\n",
      "|    neglogp        | 0.0189    |\n",
      "|    prob_true_act  | 0.986     |\n",
      "|    samples_so_far | 5456032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170997batch [2:28:41, 55.31batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 171000    |\n",
      "|    ent_loss       | -6.69e-05 |\n",
      "|    entropy        | 0.0669    |\n",
      "|    epoch          | 695       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.8e+05   |\n",
      "|    loss           | 0.0842    |\n",
      "|    neglogp        | 0.0842    |\n",
      "|    prob_true_act  | 0.954     |\n",
      "|    samples_so_far | 5472032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "171496batch [2:28:49, 54.07batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 171500    |\n",
      "|    ent_loss       | -8.17e-05 |\n",
      "|    entropy        | 0.0817    |\n",
      "|    epoch          | 697       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.8e+05   |\n",
      "|    loss           | 0.0598    |\n",
      "|    neglogp        | 0.0599    |\n",
      "|    prob_true_act  | 0.956     |\n",
      "|    samples_so_far | 5488032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "171998batch [2:28:59, 52.48batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 172000    |\n",
      "|    ent_loss       | -9.93e-07 |\n",
      "|    entropy        | 0.000993  |\n",
      "|    epoch          | 699       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.8e+05   |\n",
      "|    loss           | 8.51e-05  |\n",
      "|    neglogp        | 8.61e-05  |\n",
      "|    prob_true_act  | 1         |\n",
      "|    samples_so_far | 5504032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172497batch [2:29:08, 53.21batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 172500    |\n",
      "|    ent_loss       | -0.000112 |\n",
      "|    entropy        | 0.112     |\n",
      "|    epoch          | 701       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.8e+05   |\n",
      "|    loss           | 0.0941    |\n",
      "|    neglogp        | 0.0942    |\n",
      "|    prob_true_act  | 0.945     |\n",
      "|    samples_so_far | 5520032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172997batch [2:29:18, 45.70batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 173000    |\n",
      "|    ent_loss       | -6.43e-05 |\n",
      "|    entropy        | 0.0643    |\n",
      "|    epoch          | 703       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.8e+05   |\n",
      "|    loss           | 0.0701    |\n",
      "|    neglogp        | 0.0702    |\n",
      "|    prob_true_act  | 0.962     |\n",
      "|    samples_so_far | 5536032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "173496batch [2:29:27, 52.18batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 173500    |\n",
      "|    ent_loss       | -7.62e-05 |\n",
      "|    entropy        | 0.0762    |\n",
      "|    epoch          | 705       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.81e+05  |\n",
      "|    loss           | 0.0857    |\n",
      "|    neglogp        | 0.0857    |\n",
      "|    prob_true_act  | 0.95      |\n",
      "|    samples_so_far | 5552032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "173999batch [2:29:37, 53.70batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 174000    |\n",
      "|    ent_loss       | -2.51e-05 |\n",
      "|    entropy        | 0.0251    |\n",
      "|    epoch          | 707       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.81e+05  |\n",
      "|    loss           | 0.0204    |\n",
      "|    neglogp        | 0.0204    |\n",
      "|    prob_true_act  | 0.985     |\n",
      "|    samples_so_far | 5568032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "174497batch [2:29:46, 51.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 174500    |\n",
      "|    ent_loss       | -3.88e-05 |\n",
      "|    entropy        | 0.0388    |\n",
      "|    epoch          | 709       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.81e+05  |\n",
      "|    loss           | 0.0238    |\n",
      "|    neglogp        | 0.0238    |\n",
      "|    prob_true_act  | 0.983     |\n",
      "|    samples_so_far | 5584032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "174737batch [2:29:51, 19.43batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mbc_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jane\\wordle2\\.conda\\Lib\\site-packages\\imitation\\algorithms\\bc.py:495\u001b[0m, in \u001b[0;36mBC.train\u001b[1;34m(self, n_epochs, n_batches, on_epoch_end, on_batch_end, log_interval, log_rollouts_venv, log_rollouts_n_episodes, progress_bar, reset_tensorboard)\u001b[0m\n\u001b[0;32m    490\u001b[0m obs_tensor \u001b[38;5;241m=\u001b[39m types\u001b[38;5;241m.\u001b[39mmap_maybe_dict(\n\u001b[0;32m    491\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: util\u001b[38;5;241m.\u001b[39msafe_to_tensor(x, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mdevice),\n\u001b[0;32m    492\u001b[0m     types\u001b[38;5;241m.\u001b[39mmaybe_unwrap_dictobs(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m    493\u001b[0m )\n\u001b[0;32m    494\u001b[0m acts \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39msafe_to_tensor(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macts\u001b[39m\u001b[38;5;124m\"\u001b[39m], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 495\u001b[0m training_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_calculator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43macts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;66;03m# Renormalise the loss to be averaged over the whole\u001b[39;00m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;66;03m# batch size instead of the minibatch size.\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;66;03m# If there is an incomplete batch, its gradients will be\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;66;03m# smaller, which may be helpful for stability.\u001b[39;00m\n\u001b[0;32m    501\u001b[0m loss \u001b[38;5;241m=\u001b[39m training_metrics\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m*\u001b[39m minibatch_size \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\n",
      "File \u001b[1;32mc:\\Users\\Jane\\wordle2\\.conda\\Lib\\site-packages\\imitation\\algorithms\\bc.py:130\u001b[0m, in \u001b[0;36mBehaviorCloningLossCalculator.__call__\u001b[1;34m(self, policy, obs, acts)\u001b[0m\n\u001b[0;32m    126\u001b[0m acts \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39msafe_to_tensor(acts)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# policy.evaluate_actions's type signatures are incorrect.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# See https://github.com/DLR-RM/stable-baselines3/issues/1679\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m (_, log_prob, entropy) \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_actions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensor_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43macts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m prob_true_act \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mexp(log_prob)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m    135\u001b[0m log_prob \u001b[38;5;241m=\u001b[39m log_prob\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32mc:\\Users\\Jane\\wordle2\\.conda\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:737\u001b[0m, in \u001b[0;36mActorCriticPolicy.evaluate_actions\u001b[1;34m(self, obs, actions)\u001b[0m\n\u001b[0;32m    735\u001b[0m     latent_pi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_extractor\u001b[38;5;241m.\u001b[39mforward_actor(pi_features)\n\u001b[0;32m    736\u001b[0m     latent_vf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_extractor\u001b[38;5;241m.\u001b[39mforward_critic(vf_features)\n\u001b[1;32m--> 737\u001b[0m distribution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_action_dist_from_latent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_pi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    738\u001b[0m log_prob \u001b[38;5;241m=\u001b[39m distribution\u001b[38;5;241m.\u001b[39mlog_prob(actions)\n\u001b[0;32m    739\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_net(latent_vf)\n",
      "File \u001b[1;32mc:\\Users\\Jane\\wordle2\\.conda\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:691\u001b[0m, in \u001b[0;36mActorCriticPolicy._get_action_dist_from_latent\u001b[1;34m(self, latent_pi)\u001b[0m\n\u001b[0;32m    684\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_action_dist_from_latent\u001b[39m(\u001b[38;5;28mself\u001b[39m, latent_pi: th\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Distribution:\n\u001b[0;32m    685\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    686\u001b[0m \u001b[38;5;124;03m    Retrieve action distribution given the latent codes.\u001b[39;00m\n\u001b[0;32m    687\u001b[0m \n\u001b[0;32m    688\u001b[0m \u001b[38;5;124;03m    :param latent_pi: Latent code for the actor\u001b[39;00m\n\u001b[0;32m    689\u001b[0m \u001b[38;5;124;03m    :return: Action distribution\u001b[39;00m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 691\u001b[0m     mean_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_pi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist, DiagGaussianDistribution):\n\u001b[0;32m    694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist\u001b[38;5;241m.\u001b[39mproba_distribution(mean_actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_std)\n",
      "File \u001b[1;32mc:\\Users\\Jane\\wordle2\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jane\\wordle2\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jane\\wordle2\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bc_trainer.train(n_epochs=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current guess: SALET\n",
      "Target word: MIDST\n",
      "Attempts left: 5\n",
      "Current guess: MORIA\n",
      "Target word: MIDST\n",
      "Attempts left: 4\n",
      "Current guess: _____\n",
      "Target word: GUILT\n",
      "Attempts left: 6\n",
      "Current guess: SALET\n",
      "Target word: GUILT\n",
      "Attempts left: 5\n",
      "Current guess: CLUNG\n",
      "Target word: GUILT\n",
      "Attempts left: 4\n",
      "Current guess: _____\n",
      "Target word: EMBED\n",
      "Attempts left: 6\n",
      "Current guess: SALET\n",
      "Target word: EMBED\n",
      "Attempts left: 5\n",
      "Current guess: ROWND\n",
      "Target word: EMBED\n",
      "Attempts left: 4\n",
      "Current guess: _____\n",
      "Target word: RIDER\n",
      "Attempts left: 6\n",
      "Current guess: SALET\n",
      "Target word: RIDER\n",
      "Attempts left: 5\n",
      "Current guess: ROWND\n",
      "Target word: RIDER\n",
      "Attempts left: 4\n",
      "Current guess: _____\n",
      "Target word: OLIVE\n",
      "Attempts left: 6\n",
      "Reward after training: 11.75\n"
     ]
    }
   ],
   "source": [
    "reward_after_training, _ = evaluate_policy(bc_trainer.policy, venv, n_eval_episodes=4, render=True, return_episode_rewards=True)\n",
    "print(f\"Reward after training: {(reward_after_training)}\")\n",
    "bc_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward after training: 12.64\n"
     ]
    }
   ],
   "source": [
    "reward_after_training, _ = evaluate_policy(bc_trainer.policy, venv, 100, return_episode_rewards=True)\n",
    "print(f\"Reward after training: {np.mean(reward_after_training)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
