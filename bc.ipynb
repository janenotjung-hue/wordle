{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "from imitation.data import rollout\n",
    "from imitation.data.wrappers import RolloutInfoWrapper\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecEnvWrapper\n",
    "import numpy as np\n",
    "%reload_ext autoreload\n",
    "from Wordle import WordleEnv\n",
    "from stable_baselines3.common import monitor\n",
    "\n",
    "# Create a vectorized environment for training with `imitation`\n",
    "env = monitor.Monitor(WordleEnv())\n",
    "venv = DummyVecEnv([lambda: RolloutInfoWrapper(env)])  # Wrap a single environment -- only useful for simple testing like this\n",
    "venv.render_mode = 'human'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{3.66, 50, 94.0},\n",
       " {3.63, 95.0, 100},\n",
       " {3.52, 96.0, 150},\n",
       " {3.57, 96.0, 200},\n",
       " {3.56, 96.0, 250},\n",
       " {3.59, 96.0, 300},\n",
       " {3.56, 94.0, 350},\n",
       " {3.44, 97.0, 400},\n",
       " {3.63, 95.0, 450},\n",
       " {3.72, 90.0, 500},\n",
       " {3.65, 92.0, 550},\n",
       " {3.47, 99.0, 600},\n",
       " {3.55, 98.0, 650},\n",
       " {3.51, 97.0, 700},\n",
       " {3.63, 96.0, 750},\n",
       " {3.78, 92.0, 800},\n",
       " {3.48, 96.0, 850},\n",
       " {3.69, 96.0, 900},\n",
       " {3.5, 97.0, 950},\n",
       " {3.54, 97.0, 1000}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "from imitation.data import rollout\n",
    "from imitation.data.wrappers import RolloutInfoWrapper\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecEnvWrapper\n",
    "import numpy as np\n",
    "%reload_ext autoreload\n",
    "from Wordle import WordleEnv\n",
    "from stable_baselines3.common import monitor\n",
    "from imitation.algorithms import bc\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "import os\n",
    "import imageio\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from IPython.display import clear_output\n",
    "import sys\n",
    "\n",
    "class OutputCapturer:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.old_stdout = sys.stdout\n",
    "        self.file = open(self.filename, 'w')\n",
    "        sys.stdout = self.file\n",
    "        return self.file\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout = self.old_stdout\n",
    "        self.file.close()\n",
    "        \n",
    "env = monitor.Monitor(WordleEnv())\n",
    "venv = DummyVecEnv([lambda: RolloutInfoWrapper(env)])  # Wrap a single environment -- only useful for simple testing like this\n",
    "venv.render_mode = 'human'\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "rollouts = np.load('data/trajectories_all.npy', allow_pickle=True)\n",
    "transitions = rollout.flatten_trajectories_with_rew(rollouts)\n",
    "\n",
    "res = []\n",
    "checkpoint_arr = os.listdir(\"checkpoints/\")  # Example checkpoint path\n",
    "for i in range(len(checkpoint_arr)):\n",
    "    print()\n",
    "    checkpoint_path = f\"checkpoints/[checkpoint_arr[i]]\"  # Example checkpoint path\n",
    "\n",
    "    loaded_policy = ActorCriticPolicy.load(checkpoint_path)\n",
    "\n",
    "    bc_trainer = bc.BC(\n",
    "        observation_space=env.observation_space,\n",
    "        action_space=env.action_space,\n",
    "        demonstrations=transitions,\n",
    "        rng=rng,\n",
    "        policy=loaded_policy\n",
    "    )\n",
    "    eps = 100\n",
    "    # Use the loaded policy\n",
    "    with OutputCapturer(f\"results/[(i+1)*50]_epochs.txt\"):\n",
    "        reward_after_training, ep_length = evaluate_policy(bc_trainer.policy, venv, n_eval_episodes=eps, render=True, return_episode_rewards=True)\n",
    "        reward_after_training = [0 if x <= 0 else 10 for x in reward_after_training]\n",
    "        n = len(ep_length)\n",
    "        fails = ep_length.count(7)\n",
    "        acc = ((n - fails)/n)*100\n",
    "        print(f\"Win rate: [acc]%\")\n",
    "        print(f\"Average number of guesses: [np.mean(ep_length)]\")\n",
    "    res.append([(i+1)*50, acc, np.mean(ep_length)])\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "display(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guesses</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epc</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3.66</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3.63</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>3.52</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>3.57</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>3.56</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>3.59</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>3.56</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>3.44</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>3.63</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>3.72</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>3.65</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>3.47</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>3.55</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>3.51</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>3.63</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>3.78</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>3.48</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>3.69</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>3.50</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>3.54</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      guesses   acc\n",
       "epc                \n",
       "50       3.66  94.0\n",
       "100      3.63  95.0\n",
       "150      3.52  96.0\n",
       "200      3.57  96.0\n",
       "250      3.56  96.0\n",
       "300      3.59  96.0\n",
       "350      3.56  94.0\n",
       "400      3.44  97.0\n",
       "450      3.63  95.0\n",
       "500      3.72  90.0\n",
       "550      3.65  92.0\n",
       "600      3.47  99.0\n",
       "650      3.55  98.0\n",
       "700      3.51  97.0\n",
       "750      3.63  96.0\n",
       "800      3.78  92.0\n",
       "850      3.48  96.0\n",
       "900      3.69  96.0\n",
       "950      3.50  97.0\n",
       "1000     3.54  97.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "arr = [[3.66, 94.0, 50],\n",
    " [3.63, 95.0, 100],\n",
    " [3.52, 96.0, 150],\n",
    " [3.57, 96.0, 200],\n",
    " [3.56, 96.0, 250],\n",
    " [3.59, 96.0, 300],\n",
    " [3.56, 94.0, 350],\n",
    " [3.44, 97.0, 400],\n",
    " [3.63, 95.0, 450],\n",
    " [3.72, 90.0, 500],\n",
    " [3.65, 92.0, 550],\n",
    " [3.47, 99.0, 600],\n",
    " [3.55, 98.0, 650],\n",
    " [3.51, 97.0, 700],\n",
    " [3.63, 96.0, 750],\n",
    " [3.78, 92.0, 800],\n",
    " [3.48, 96.0, 850],\n",
    " [3.69, 96.0, 900],\n",
    " [3.5, 97.0, 950],\n",
    " [3.54, 97.0, 1000]]\n",
    "\n",
    "columns = [\"guesses\", \"acc\", \"epc\"]\n",
    "df = pd.DataFrame(arr, columns=columns)\n",
    "\n",
    "cols = list(df.columns)\n",
    "cols.insert(0, cols.pop(2))  # Move the third column to the first position\n",
    "\n",
    "df = df[cols].set_index(cols[0])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('extracted_data.csv')\n",
    "plt.plot(df.index, df['loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.title('Loss Over Epoch')\n",
    "\n",
    "for i in range (0, 21):\n",
    "    plt.axvline(x=i*50, color='grey', linestyle='--', linewidth=0.1)  # Customize line properties as needed\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "rollouts = np.load('data/trajectories_all.npy', allow_pickle=True)\n",
    "transitions = rollout.flatten_trajectories_with_rew(rollouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imitation.algorithms import bc\n",
    "\n",
    "bc_trainer = bc.BC(\n",
    "    observation_space=env.observation_space,\n",
    "    action_space=env.action_space,\n",
    "    demonstrations=transitions,\n",
    "    rng=rng,\n",
    ")\n",
    "reward_before_training, _ = evaluate_policy(bc_trainer.policy, venv, 100, return_episode_rewards=True)\n",
    "print(f\"Reward before training: [np.mean(reward_before_training)]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "161496batch [2:25:47, 58.40batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 161500    |\n",
      "|    ent_loss       | -3.91e-05 |\n",
      "|    entropy        | 0.0391    |\n",
      "|    epoch          | 656       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.77e+05  |\n",
      "|    loss           | 0.0336    |\n",
      "|    neglogp        | 0.0336    |\n",
      "|    prob_true_act  | 0.979     |\n",
      "|    samples_so_far | 5168032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "161998batch [2:25:57, 53.29batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 162000    |\n",
      "|    ent_loss       | -1.66e-06 |\n",
      "|    entropy        | 0.00166   |\n",
      "|    epoch          | 658       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.77e+05  |\n",
      "|    loss           | 0.000147  |\n",
      "|    neglogp        | 0.000149  |\n",
      "|    prob_true_act  | 1         |\n",
      "|    samples_so_far | 5184032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162496batch [2:26:06, 54.94batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 162500    |\n",
      "|    ent_loss       | -4.19e-06 |\n",
      "|    entropy        | 0.00419   |\n",
      "|    epoch          | 660       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.77e+05  |\n",
      "|    loss           | 0.000623  |\n",
      "|    neglogp        | 0.000628  |\n",
      "|    prob_true_act  | 0.999     |\n",
      "|    samples_so_far | 5200032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162994batch [2:26:15, 57.34batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 163000    |\n",
      "|    ent_loss       | -1.42e-06 |\n",
      "|    entropy        | 0.00142   |\n",
      "|    epoch          | 662       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.78e+05  |\n",
      "|    loss           | 0.000129  |\n",
      "|    neglogp        | 0.000131  |\n",
      "|    prob_true_act  | 1         |\n",
      "|    samples_so_far | 5216032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163494batch [2:26:24, 60.12batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 163500    |\n",
      "|    ent_loss       | -0.000102 |\n",
      "|    entropy        | 0.102     |\n",
      "|    epoch          | 664       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.78e+05  |\n",
      "|    loss           | 0.11      |\n",
      "|    neglogp        | 0.111     |\n",
      "|    prob_true_act  | 0.939     |\n",
      "|    samples_so_far | 5232032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163996batch [2:26:32, 59.12batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 164000    |\n",
      "|    ent_loss       | -3.08e-05 |\n",
      "|    entropy        | 0.0308    |\n",
      "|    epoch          | 666       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.78e+05  |\n",
      "|    loss           | 0.0411    |\n",
      "|    neglogp        | 0.0411    |\n",
      "|    prob_true_act  | 0.977     |\n",
      "|    samples_so_far | 5248032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164499batch [2:26:41, 56.28batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 164500    |\n",
      "|    ent_loss       | -1.08e-06 |\n",
      "|    entropy        | 0.00108   |\n",
      "|    epoch          | 668       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.78e+05  |\n",
      "|    loss           | 9.06e-05  |\n",
      "|    neglogp        | 9.17e-05  |\n",
      "|    prob_true_act  | 1         |\n",
      "|    samples_so_far | 5264032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164999batch [2:26:57, 18.93batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 165000    |\n",
      "|    ent_loss       | -4.13e-06 |\n",
      "|    entropy        | 0.00413   |\n",
      "|    epoch          | 670       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.78e+05  |\n",
      "|    loss           | 0.000427  |\n",
      "|    neglogp        | 0.000431  |\n",
      "|    prob_true_act  | 1         |\n",
      "|    samples_so_far | 5280032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "165496batch [2:27:05, 60.57batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 165500    |\n",
      "|    ent_loss       | -3.64e-06 |\n",
      "|    entropy        | 0.00364   |\n",
      "|    epoch          | 672       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.78e+05  |\n",
      "|    loss           | 0.00036   |\n",
      "|    neglogp        | 0.000363  |\n",
      "|    prob_true_act  | 1         |\n",
      "|    samples_so_far | 5296032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "165998batch [2:27:14, 57.10batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "| batch_size        | 32       |\n",
      "| bc/               |          |\n",
      "|    batch          | 166000   |\n",
      "|    ent_loss       | -2.9e-06 |\n",
      "|    entropy        | 0.0029   |\n",
      "|    epoch          | 674      |\n",
      "|    l2_loss        | 0        |\n",
      "|    l2_norm        | 1.78e+05 |\n",
      "|    loss           | 0.000263 |\n",
      "|    neglogp        | 0.000266 |\n",
      "|    prob_true_act  | 1        |\n",
      "|    samples_so_far | 5312032  |\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "166496batch [2:27:23, 61.09batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 166500    |\n",
      "|    ent_loss       | -3.49e-05 |\n",
      "|    entropy        | 0.0349    |\n",
      "|    epoch          | 676       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.78e+05  |\n",
      "|    loss           | 0.0175    |\n",
      "|    neglogp        | 0.0176    |\n",
      "|    prob_true_act  | 0.986     |\n",
      "|    samples_so_far | 5328032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "166998batch [2:27:31, 55.01batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 167000    |\n",
      "|    ent_loss       | -1.35e-06 |\n",
      "|    entropy        | 0.00135   |\n",
      "|    epoch          | 678       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.79e+05  |\n",
      "|    loss           | 0.000122  |\n",
      "|    neglogp        | 0.000123  |\n",
      "|    prob_true_act  | 1         |\n",
      "|    samples_so_far | 5344032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167495batch [2:27:40, 58.20batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "| batch_size        | 32       |\n",
      "| bc/               |          |\n",
      "|    batch          | 167500   |\n",
      "|    ent_loss       | -1.5e-06 |\n",
      "|    entropy        | 0.0015   |\n",
      "|    epoch          | 680      |\n",
      "|    l2_loss        | 0        |\n",
      "|    l2_norm        | 1.79e+05 |\n",
      "|    loss           | 0.000137 |\n",
      "|    neglogp        | 0.000139 |\n",
      "|    prob_true_act  | 1        |\n",
      "|    samples_so_far | 5360032  |\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167998batch [2:27:49, 57.76batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 168000    |\n",
      "|    ent_loss       | -1.57e-06 |\n",
      "|    entropy        | 0.00157   |\n",
      "|    epoch          | 682       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.79e+05  |\n",
      "|    loss           | 0.000139  |\n",
      "|    neglogp        | 0.00014   |\n",
      "|    prob_true_act  | 1         |\n",
      "|    samples_so_far | 5376032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168497batch [2:27:57, 60.18batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "| batch_size        | 32       |\n",
      "| bc/               |          |\n",
      "|    batch          | 168500   |\n",
      "|    ent_loss       | -2.2e-05 |\n",
      "|    entropy        | 0.022    |\n",
      "|    epoch          | 684      |\n",
      "|    l2_loss        | 0        |\n",
      "|    l2_norm        | 1.79e+05 |\n",
      "|    loss           | 0.0353   |\n",
      "|    neglogp        | 0.0353   |\n",
      "|    prob_true_act  | 0.979    |\n",
      "|    samples_so_far | 5392032  |\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168994batch [2:28:05, 59.47batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 169000    |\n",
      "|    ent_loss       | -8.81e-06 |\n",
      "|    entropy        | 0.00881   |\n",
      "|    epoch          | 686       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.79e+05  |\n",
      "|    loss           | 0.00113   |\n",
      "|    neglogp        | 0.00114   |\n",
      "|    prob_true_act  | 0.999     |\n",
      "|    samples_so_far | 5408032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169494batch [2:28:14, 60.93batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 169500    |\n",
      "|    ent_loss       | -3.78e-06 |\n",
      "|    entropy        | 0.00378   |\n",
      "|    epoch          | 689       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.79e+05  |\n",
      "|    loss           | 0.000378  |\n",
      "|    neglogp        | 0.000382  |\n",
      "|    prob_true_act  | 1         |\n",
      "|    samples_so_far | 5424032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169998batch [2:28:22, 60.19batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 170000    |\n",
      "|    ent_loss       | -8.92e-07 |\n",
      "|    entropy        | 0.000892  |\n",
      "|    epoch          | 691       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.79e+05  |\n",
      "|    loss           | 7.53e-05  |\n",
      "|    neglogp        | 7.62e-05  |\n",
      "|    prob_true_act  | 1         |\n",
      "|    samples_so_far | 5440032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170499batch [2:28:32, 44.52batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 170500    |\n",
      "|    ent_loss       | -2.53e-05 |\n",
      "|    entropy        | 0.0253    |\n",
      "|    epoch          | 693       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.79e+05  |\n",
      "|    loss           | 0.0188    |\n",
      "|    neglogp        | 0.0189    |\n",
      "|    prob_true_act  | 0.986     |\n",
      "|    samples_so_far | 5456032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170997batch [2:28:41, 55.31batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 171000    |\n",
      "|    ent_loss       | -6.69e-05 |\n",
      "|    entropy        | 0.0669    |\n",
      "|    epoch          | 695       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.8e+05   |\n",
      "|    loss           | 0.0842    |\n",
      "|    neglogp        | 0.0842    |\n",
      "|    prob_true_act  | 0.954     |\n",
      "|    samples_so_far | 5472032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "171496batch [2:28:49, 54.07batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 171500    |\n",
      "|    ent_loss       | -8.17e-05 |\n",
      "|    entropy        | 0.0817    |\n",
      "|    epoch          | 697       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.8e+05   |\n",
      "|    loss           | 0.0598    |\n",
      "|    neglogp        | 0.0599    |\n",
      "|    prob_true_act  | 0.956     |\n",
      "|    samples_so_far | 5488032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "171998batch [2:28:59, 52.48batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 172000    |\n",
      "|    ent_loss       | -9.93e-07 |\n",
      "|    entropy        | 0.000993  |\n",
      "|    epoch          | 699       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.8e+05   |\n",
      "|    loss           | 8.51e-05  |\n",
      "|    neglogp        | 8.61e-05  |\n",
      "|    prob_true_act  | 1         |\n",
      "|    samples_so_far | 5504032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172497batch [2:29:08, 53.21batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 172500    |\n",
      "|    ent_loss       | -0.000112 |\n",
      "|    entropy        | 0.112     |\n",
      "|    epoch          | 701       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.8e+05   |\n",
      "|    loss           | 0.0941    |\n",
      "|    neglogp        | 0.0942    |\n",
      "|    prob_true_act  | 0.945     |\n",
      "|    samples_so_far | 5520032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172997batch [2:29:18, 45.70batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 173000    |\n",
      "|    ent_loss       | -6.43e-05 |\n",
      "|    entropy        | 0.0643    |\n",
      "|    epoch          | 703       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.8e+05   |\n",
      "|    loss           | 0.0701    |\n",
      "|    neglogp        | 0.0702    |\n",
      "|    prob_true_act  | 0.962     |\n",
      "|    samples_so_far | 5536032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "173496batch [2:29:27, 52.18batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 173500    |\n",
      "|    ent_loss       | -7.62e-05 |\n",
      "|    entropy        | 0.0762    |\n",
      "|    epoch          | 705       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.81e+05  |\n",
      "|    loss           | 0.0857    |\n",
      "|    neglogp        | 0.0857    |\n",
      "|    prob_true_act  | 0.95      |\n",
      "|    samples_so_far | 5552032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "173999batch [2:29:37, 53.70batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 174000    |\n",
      "|    ent_loss       | -2.51e-05 |\n",
      "|    entropy        | 0.0251    |\n",
      "|    epoch          | 707       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.81e+05  |\n",
      "|    loss           | 0.0204    |\n",
      "|    neglogp        | 0.0204    |\n",
      "|    prob_true_act  | 0.985     |\n",
      "|    samples_so_far | 5568032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "174497batch [2:29:46, 51.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| batch_size        | 32        |\n",
      "| bc/               |           |\n",
      "|    batch          | 174500    |\n",
      "|    ent_loss       | -3.88e-05 |\n",
      "|    entropy        | 0.0388    |\n",
      "|    epoch          | 709       |\n",
      "|    l2_loss        | 0         |\n",
      "|    l2_norm        | 1.81e+05  |\n",
      "|    loss           | 0.0238    |\n",
      "|    neglogp        | 0.0238    |\n",
      "|    prob_true_act  | 0.983     |\n",
      "|    samples_so_far | 5584032   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "174737batch [2:29:51, 19.43batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mbc_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jane\\wordle2\\.conda\\Lib\\site-packages\\imitation\\algorithms\\bc.py:495\u001b[0m, in \u001b[0;36mBC.train\u001b[1;34m(self, n_epochs, n_batches, on_epoch_end, on_batch_end, log_interval, log_rollouts_venv, log_rollouts_n_episodes, progress_bar, reset_tensorboard)\u001b[0m\n\u001b[0;32m    490\u001b[0m obs_tensor \u001b[38;5;241m=\u001b[39m types\u001b[38;5;241m.\u001b[39mmap_maybe_dict(\n\u001b[0;32m    491\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: util\u001b[38;5;241m.\u001b[39msafe_to_tensor(x, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mdevice),\n\u001b[0;32m    492\u001b[0m     types\u001b[38;5;241m.\u001b[39mmaybe_unwrap_dictobs(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m    493\u001b[0m )\n\u001b[0;32m    494\u001b[0m acts \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39msafe_to_tensor(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macts\u001b[39m\u001b[38;5;124m\"\u001b[39m], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 495\u001b[0m training_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_calculator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43macts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;66;03m# Renormalise the loss to be averaged over the whole\u001b[39;00m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;66;03m# batch size instead of the minibatch size.\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;66;03m# If there is an incomplete batch, its gradients will be\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;66;03m# smaller, which may be helpful for stability.\u001b[39;00m\n\u001b[0;32m    501\u001b[0m loss \u001b[38;5;241m=\u001b[39m training_metrics\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m*\u001b[39m minibatch_size \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\n",
      "File \u001b[1;32mc:\\Users\\Jane\\wordle2\\.conda\\Lib\\site-packages\\imitation\\algorithms\\bc.py:130\u001b[0m, in \u001b[0;36mBehaviorCloningLossCalculator.__call__\u001b[1;34m(self, policy, obs, acts)\u001b[0m\n\u001b[0;32m    126\u001b[0m acts \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39msafe_to_tensor(acts)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# policy.evaluate_actions's type signatures are incorrect.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# See https://github.com/DLR-RM/stable-baselines3/issues/1679\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m (_, log_prob, entropy) \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_actions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensor_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43macts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m prob_true_act \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mexp(log_prob)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m    135\u001b[0m log_prob \u001b[38;5;241m=\u001b[39m log_prob\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32mc:\\Users\\Jane\\wordle2\\.conda\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:737\u001b[0m, in \u001b[0;36mActorCriticPolicy.evaluate_actions\u001b[1;34m(self, obs, actions)\u001b[0m\n\u001b[0;32m    735\u001b[0m     latent_pi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_extractor\u001b[38;5;241m.\u001b[39mforward_actor(pi_features)\n\u001b[0;32m    736\u001b[0m     latent_vf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_extractor\u001b[38;5;241m.\u001b[39mforward_critic(vf_features)\n\u001b[1;32m--> 737\u001b[0m distribution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_action_dist_from_latent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_pi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    738\u001b[0m log_prob \u001b[38;5;241m=\u001b[39m distribution\u001b[38;5;241m.\u001b[39mlog_prob(actions)\n\u001b[0;32m    739\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_net(latent_vf)\n",
      "File \u001b[1;32mc:\\Users\\Jane\\wordle2\\.conda\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:691\u001b[0m, in \u001b[0;36mActorCriticPolicy._get_action_dist_from_latent\u001b[1;34m(self, latent_pi)\u001b[0m\n\u001b[0;32m    684\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_action_dist_from_latent\u001b[39m(\u001b[38;5;28mself\u001b[39m, latent_pi: th\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Distribution:\n\u001b[0;32m    685\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    686\u001b[0m \u001b[38;5;124;03m    Retrieve action distribution given the latent codes.\u001b[39;00m\n\u001b[0;32m    687\u001b[0m \n\u001b[0;32m    688\u001b[0m \u001b[38;5;124;03m    :param latent_pi: Latent code for the actor\u001b[39;00m\n\u001b[0;32m    689\u001b[0m \u001b[38;5;124;03m    :return: Action distribution\u001b[39;00m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 691\u001b[0m     mean_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_pi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist, DiagGaussianDistribution):\n\u001b[0;32m    694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist\u001b[38;5;241m.\u001b[39mproba_distribution(mean_actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_std)\n",
      "File \u001b[1;32mc:\\Users\\Jane\\wordle2\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jane\\wordle2\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jane\\wordle2\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bc_trainer.train(n_epochs=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current guess: SALET\n",
      "Target word: AGONY\n",
      "Attempts left: 5\n",
      "Current guess: BROND\n",
      "Target word: AGONY\n",
      "Attempts left: 4\n",
      "Current guess: _____\n",
      "Target word: WIDTH\n",
      "Attempts left: 6\n",
      "Current guess: SALET\n",
      "Target word: WIDTH\n",
      "Attempts left: 5\n",
      "Current guess: NORTH\n",
      "Target word: WIDTH\n",
      "Attempts left: 4\n",
      "Current guess: FIFTH\n",
      "Target word: WIDTH\n",
      "Attempts left: 3\n",
      "Current guess: _____\n",
      "Target word: PERKY\n",
      "Attempts left: 6\n",
      "Current guess: SALET\n",
      "Target word: PERKY\n",
      "Attempts left: 5\n",
      "Current guess: DRONE\n",
      "Target word: PERKY\n",
      "Attempts left: 4\n",
      "Current guess: MURRY\n",
      "Target word: PERKY\n",
      "Attempts left: 3\n",
      "Current guess: JERKY\n",
      "Target word: PERKY\n",
      "Attempts left: 2\n",
      "Current guess: _____\n",
      "Target word: VERVE\n",
      "Attempts left: 6\n",
      "Current guess: SALET\n",
      "Target word: VERVE\n",
      "Attempts left: 5\n",
      "Current guess: DRONE\n",
      "Target word: VERVE\n",
      "Attempts left: 4\n",
      "Current guess: VERGE\n",
      "Target word: VERVE\n",
      "Attempts left: 3\n",
      "Current guess: _____\n",
      "Target word: IMPLY\n",
      "Attempts left: 6\n",
      "Reward after training: [12.0, 15.0, 16.0, 15.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<imitation.algorithms.bc.BC at 0x27636f3ce90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_after_training, _ = evaluate_policy(bc_trainer.policy, venv, n_eval_episodes=4, render=True, return_episode_rewards=True)\n",
    "print(f\"Reward after training: [(reward_after_training)]\")\n",
    "bc_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward after training: 12.35\n"
     ]
    }
   ],
   "source": [
    "reward_after_training, _ = evaluate_policy(bc_trainer.policy, venv, 100, return_episode_rewards=True)\n",
    "print(f\"Reward after training: [np.mean(reward_after_training)]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
